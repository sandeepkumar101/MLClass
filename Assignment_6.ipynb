{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Random Forest Classifiers\n",
    "-------  \n",
    "\n",
    "## Project Guide  \n",
    "------------  \n",
    "- [Project Overview](#project-overview)  \n",
    "- [Part 1: Acquire, Explore, and Preprocess Data](#part1)\n",
    "- [Part 2: Trees and Forests](#part2)\n",
    "- [Part 3: Parameter Tuning](#part3)\n",
    "\n",
    "<a id = \"project-overview\".></a>\n",
    "## Project Overview\n",
    "-------\n",
    "#### EXPECTED TIME: 2 HRS  \n",
    "\n",
    "\n",
    "This assignment uses a variety of decision tree based classifiers to attempt prediction of whether or not a customer will default on their loans. Our data comes from [the UCI machine learning Repository](https://archive.ics.uci.edu/ml/index.php) on [default of credit card clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#)  \n",
    "\n",
    "Activities will include:  \n",
    "- Manipulating DataFrames  \n",
    "- Visualizing data  \n",
    "- Calculation of impurity measures  \n",
    "- Using `sklearn`'s tree and forest models  \n",
    "- Evaluate the effects of hyperparameter tuning  \n",
    "\n",
    "\n",
    "**Motivation**: Decision Trees and Forests offer easy to understand yet fairly advanced models with a variety of hyper-parameters to increase or decrease complexity to tune between bias and variance\n",
    "\n",
    "**Problem**:  \n",
    "Given a number of personal variables, (sex, education, marriage status, age); and recent payment history, attempt to predict whether or not a customer will default in the next month.   \n",
    "\n",
    "**Data**:[Defaults of credit card clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#)  \n",
    "\n",
    "Please see above link for a complete description of the  data.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "Data Set Information:\n",
    "\n",
    "This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel â€œSorting Smoothing Methodâ€ to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "X2: Gender (1 = male; 2 = female). \n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "X5: Age (year). \n",
    "X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. \n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "## Part 1: Acquire, Explore, and Preprocess Data\n",
    "----  \n",
    "\n",
    "#### Import / Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "              ...              BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "0             ...                      0          0          0         0   \n",
       "1             ...                   3272       3455       3261         0   \n",
       "2             ...                  14331      14948      15549      1518   \n",
       "3             ...                  28314      28959      29547      2000   \n",
       "4             ...                  20940      19146      19131      2000   \n",
       "\n",
       "   PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0       689         0         0         0         0   \n",
       "1      1000      1000      1000         0      2000   \n",
       "2      1500      1000      1000      1000      5000   \n",
       "3      2019      1200      1100      1069      1000   \n",
       "4     36681     10000      9000       689       679   \n",
       "\n",
       "   default payment next month  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in Data\n",
    "df = pd.read_excel(\"../resource/asnlib/publicdata/default of credit card clients.xls\", header = 1)\n",
    "\n",
    "df.rename(columns = {\"PAY_0\":\"PAY_1\"}, inplace = True) #renaming mis-named column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Explore the Data  \n",
    "#### Check for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Data Shape: \" , df.shape, \"\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Appears no null data.\n",
    "    \n",
    "### Investigate Categorical Variables  \n",
    "#### Question 1:\n",
    "The \"`default payment next month`\" will be the target used for classification. Investigate its distribution for the question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### Assign an int to `ans0` corresponding to the total number of non-default records\n",
    "### Assign an int to `ans1` corresponding to the total number of default records\n",
    "\n",
    "### Note the a \"0\" in the 'default payments next month' column means \"non-default\" and a 1 means \"default\"\n",
    "\n",
    "### YOUR ANSWERS BELOW\n",
    "\n",
    "ans0 = 0\n",
    "ans1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 1",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### This proportion of default and non-default records means we are dealing with \n",
    "\n",
    "### 'a') Balanced classes\n",
    "### 'b') Unbalanced classes\n",
    "### Assign the character associated with your choice as a string to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 2",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Investigating the Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note: The code-book only describes the education variable as having four values (1-4), yet, here, there are seven values (0-6).  \n",
    "In some cases this might be grounds to throw out these unknown values (0,5,6). For now, we will leave them in, assuming that they have some (unknown to us) meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df['MARRIAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note: Again, the code book only describes three values for marriage (1-3), yet here, \"0\" also appears. Given what we saw above, we might assume the \"0\" in these categorical variables is functionally used for the \"null\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note: A slight imbalance exists representation of men and women, with women making up a little over 60% of our observations. Thankfully this column contains no \"0\"s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### A Closer look at the \"PAY\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df['PAY_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "### True or False:\n",
    "### The code-book (description of variables that came with the data set; copied above and in link)\n",
    "### described what a \"0\" in the 'Pay_#' columns means?\n",
    "\n",
    "### Assign boolean answer to ans1\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 3",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Investigate relationship between \"Pay\", \"Bill_amt\" and \"Pay_amt\" variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for i in [-2,-1,0,1,2,8]:\n",
    "    print(df[df['PAY_1']==i][['PAY_1','BILL_AMT1','PAY_AMT1']].head(8), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    " Unclear exactly how these \"PAY\" variables work. Possibly they should be treated as categorical data instead of discrete and interval data, but, for this modeling task, keep them as interval data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Define function for creating histograms\n",
    "def pay_hist(df, cols, ymax):\n",
    "    plt.figure(figsize= (10,7)) # define fig size\n",
    "    \n",
    "    for index, col in enumerate(cols): # For each column passed to function\n",
    "        plt.subplot(2,3, index +1) # plot on new subplot\n",
    "        plt.ylim(ymax = ymax) # standardize ymax\n",
    "        plt.hist(df[col]) # create hist\n",
    "        plt.title(col) # title with column names\n",
    "    plt.tight_layout(); # make sure titles don't overlap\n",
    "\n",
    "pay_cols = [\"PAY_\"+str(n) for n in range(1,7)]\n",
    "pay_amt_cols = ['PAY_AMT' + str(n) for n in range(1,7)]\n",
    "bill_amt_cols = ['BILL_AMT' + str(n) for n in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pay_hist(df, pay_cols, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note: Clearly the \"0\" is the majority class for all of the \"PAY\" variables. But, unclear what a \"0\" means as it is not in the code book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pay_hist(df, pay_amt_cols, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df[pay_amt_cols].boxplot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_no_0_pay_amt_1 = df[df[\"PAY_AMT1\"]!=0]\n",
    "df_no_0_pay_amt_1[\"PAY_AMT1\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Even taking out all the PAY_AMT of 0, most payments stay close to 0 with a long tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "log_pay_amt1 = np.log10(df_no_0_pay_amt_1[\"PAY_AMT1\"])\n",
    "plt.hist(log_pay_amt1)\n",
    "plt.title(\"Log10-Transformed values for 'PAY_AMT1' (Excluding 0s)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Log Transformation (used above) or $\\sqrt[4]{x}$ transformations (which automatically deals with 0s) can be a good way of looking more closely at skewed data. Above, we see that most of the repayment amounts are in the 1000's of dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pay_hist(df, bill_amt_cols, 23000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df[bill_amt_cols].boxplot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Preprocessing\n",
    "Currently \"Sex\" is coded as 2 for \"female\" and 1 for \"male\". As this is encoded as binary we will change the column name to \"FEMALE\" and subtract 1 from each value - thus 1 will be \"Female\" and 0 \"Male\".\n",
    "\n",
    "Both Education and Marriage are categorical with multiple options. `pd.get_dummies()` will allow us to create n-1 binary features to encode the n categories.  \n",
    "\n",
    "#### Note regarding `get_dummies()`\n",
    "`pd.get_dummies()` is **NOT** appropriate in many ML applications.  \n",
    "\n",
    "For Example: Currently we have the values 0-6 in the \"EDUCATION\" feature. Suppose that when we split the training and test data, all 14 of the \"0\" values ended up in the test set. Running `pd.get_dummies()` on the test set would add 6 columns where the training set would only have 5 columns added from that action. then, whatever model had been fit would not know how to deal that new feature / category.  \n",
    "\n",
    "The function is used here for simplicities' sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df['SEX'] = df['SEX']-1 # change vals of 'sex' to 0,1\n",
    "\n",
    "df.rename(columns = {'SEX':'FEMALE', \"default payment next month\":\"default\"}, inplace = True) # rename col names\n",
    "\n",
    "for col, pre in zip([\"EDUCATION\", \"MARRIAGE\"],[\"EDU\",\"MAR\"]): # get dummies and rename cols for ed and marraige\n",
    "    df = pd.concat([\n",
    "        df.drop(col, axis = \"columns\"), pd.get_dummies(df[col], prefix = pre, drop_first = True)],\n",
    "    axis = 'columns')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Why is it inappropriate to use `pd.get_dummies()` when preprocessing data?\n",
    "\n",
    "### 'a') it destroys data by removing categorical data\n",
    "### 'b') it will skew results of models\n",
    "### 'c') it cannot deal with \"new\" categories possibly found in a test set\n",
    "### 'd') it is not a real method\n",
    "### Assign character corresponding to your choice as string to ans1.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 4",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Why are 'dummy' variables necessary?\n",
    "\n",
    "### 'a') It helps to expand the number of features\n",
    "### 'b') Models cannot deal multi-class categorical data\n",
    "### 'c') It translates categorical data into quantitative data\n",
    "### Assign character corresponding to your choice as string to ans1.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 5",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"part2\"></a>\n",
    "## Trees and Forests: Intro\n",
    "\n",
    "Given a target (categorical or continuous), a decision tree iteratively splits data. It splits data at the value in whichever feature that creates the greatest separation among the target variable.\n",
    "\n",
    "For example, say the target variable on a dataset of professional basketball players is league: NBA and WNBA. The available features are height and weight.  \n",
    "\n",
    "Split 1: Although there are WNBA players over 6'8\" tall, that is very rare. Thus, a decision tree might  split the data at the height of 6'8\", 6'7\" or 6'6\". At that split the tree would predict that any basketball player over 6'6\" plays in the NBA.  \n",
    "\n",
    "Split 2: For players shorter than 6'6\", the tree might decide to split that data again at 5'10\" and predict that basketball players under 5'10\" play in the WNBA.  \n",
    "\n",
    "Split 3: For those players between 5'10\" and 6'6\", maybe the tree might discriminate on weight, predicting that all those players who weigh more than 180 Lbs. play in the NBA.  \n",
    "\n",
    "The resulting tree could be visualized as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![DTExample](./assets/DTExample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Depth\n",
    "\n",
    "The above tree has a depth of 2.  \n",
    "The maximum depth to which a is allowed to grow can be specified with `max_depth` in `sklearn`. By default, `max_depth` it is set to `None` which means the tree will grow until all leaves (terminal nodes) are pure, or until other user-specified criteria are met. Importantly, `max_depth` can impact the amount of time it takes to build a tree (this becomes especially important when starting to work with forests.)  \n",
    "\n",
    "### Splitting\n",
    "\n",
    "The splits in the above trees were determined intuitively. Thankfully decision Trees do not make their decisions using intuition. In the `sklearn` package two splitting criterion are available for classifiers; \"gini\" and \"entropy\". In general, \"gini\" splitting favors larger partitions, where \"entropy\" favors splitting of smaller groups that are of a single class. \n",
    "\n",
    "[More on Gini/Entropy](http://www.learnbymarketing.com/481/decision-tree-flavors-gini-info-gain/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Gini and Entropy Calculations\n",
    "\n",
    "<table><tr><td><img src='./assets/choc.png' style=\"width: 70%;\"></td><td><img src='./assets/choc2.png' style=\"width: 70%;\"></td></tr></table>  \n",
    "\n",
    "\n",
    "Above we have a split in a data set regarding good and bad chocolate.  \n",
    "\n",
    "You will be asked to calculate the gini impurity in the next questions.  \n",
    "\n",
    "The Split on \"American\" shows 175 good chocolates and 330 bad chocolates where `American == True`. There are 200 good and 120 bad chocolates where `American == False`  \n",
    "\n",
    "The Split on \"German\" shows 110 good chocolates and 60 bad chocolates where `German == True`. There are 285 good and 390 bad chocolates where `German == False`\n",
    "\n",
    "As a reminder; the gini-index for a node is: $$1- \\sum_{j=1}^n p^2_j$$  \n",
    "Where there are n classes and $p_j$ is the frequency of class j in that node.  \n",
    "Finally, the indexes for each of these nodes is weighted by the proportion of data at each node, then summed.  \n",
    "Remember gini-indicies closer to 0 are more \"pure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Calculate the gini impurity for the split on 'American'.\n",
    "\n",
    "### Answer will be tested to 4 decimal places\n",
    "### Assign float answer to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 6",
     "locked": true,
     "points": "15",
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Same instructions as above, but this time, calculate gini impurity for split on `German`\n",
    "### Assign float answer to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 7",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### According to the gini values calcualted above, which split is better?\n",
    "\n",
    "### 'a') American\n",
    "### 'b') German\n",
    "### Assign character associated with your choice as string to ans1.\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 8",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Forests\n",
    "\n",
    "\"Forests\" are collections of decision trees designed to protect against over-fitting.  \n",
    "A single decision tree (particularly one that is allowed to grow to any depth), may be prone to overfitting. Algorithmically, the tree is designed to continue to make splits until it has completely classified all of the available data, and/or exhausted every possible split. Thus, no complexity and no particular is too fine for the tree to split upon. A tree might be \"pruned\" (by setting max_depth) to protect against over fitting, but, a \"forest\" of trees might also be used instead.  \n",
    "\n",
    "### Building Tree / Forest Models  \n",
    "#### Question 9:\n",
    "Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Assume we are predicting default/not-default.\n",
    "### What percent (int between 0 and 100) of observations would be correctly predicted if the majority class\n",
    "### were predicted every time.\n",
    "### E.g., What is the baseline accuracy?\n",
    "### Assign int to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 9",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Import models and metrics; create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create tts \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(\"default\", axis = 'columns'), df['default'],\n",
    "    test_size = .3, random_state = 1738)\n",
    "\n",
    "# Instantiate tree and forest models\n",
    "dt = DecisionTreeClassifier()\n",
    "bag = BaggingClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Look at performance of classifiers using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)\n",
    "print(\"Decision Tree: \\n\", classification_report(y_test, dt.predict(X_test)), \"\\n\")\n",
    "\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "print(\"Bagging: \\n\", classification_report(y_test, bag.predict(X_test)), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"-----------\")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Random Forest: \\n\", classification_report(y_test, rf.predict(X_test)), \"\\n\")\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "et.fit(X_train, y_train)\n",
    "print(\"Extra Trees: \\n\", classification_report(y_test, et.predict(X_test)), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 10\n",
    "Values of different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### Are all predictions in this data set equal in business value?\n",
    "### e.g. is correctly predicting a \"default\" as valuable as predicting a \"non-default\"\n",
    "### 'a') Equal values\n",
    "### 'b') Unequal values\n",
    "### Assign string associated with your choice to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"part3\"></a>\n",
    "\n",
    "## Part 3: Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It appears both the Random Forest and the Extra Trees perform in a similarly effective manner. For this section, we will try to increase the performance of the Random Forest by tuning a couple hyper parameters, namely `criterion` and `estimators`\n",
    "\n",
    "Because we are more interested in forecasting defaults than non-defaults, we will optimize on the recall of defaults -- recall is the proportion of defaults predicted over total defaults.  \n",
    "\n",
    "The below will not run on Vocareum due to processing constraints, thus the output is copied below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.metrics import recall_score\n",
    "# criterion = ['gini', 'entropy']\n",
    "# n_estimators = [5,10,20, 50, 100]\n",
    "# scores = dict()\n",
    "# i = 0\n",
    "# for c in criterion:\n",
    "#     for e in n_estimators:\n",
    "#         rf = RandomForestClassifier(n_estimators = e, criterion = c, random_state = 1738)\n",
    "#         rf.fit(X_train, y_train)\n",
    "#         scores[i] = {'recall':recall_score(y_test, rf.predict(X_test)), 'trees' :e, \"crit\":c}\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![recallScores](./assets/recallScores3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### According to the output shown in the picture above, the model with the best recall score featured: \n",
    "### How many trees? Answer with int assigned to ans1.\n",
    "\n",
    "### Which splitting method?\n",
    "### 'a') entropy or 'b')gini.\n",
    "### Put the character coressponding to your selection as a string in ans2\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = 0\n",
    "ans2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 11",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "With a general sense that maybe a `RandomForestClassifier` will perform best using `gini` splittling with somewhere around 5 trees, further hyper-parameter tuning below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# n_estimators = [1,2,3,4,5,6,7,8]\n",
    "# scores2 = dict()\n",
    "# i = 0\n",
    "# for e in n_estimators:\n",
    "#     rf = RandomForestClassifier(n_estimators = e, criterion = 'gini', random_state = 1738)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     scores2[i] = {'recall':recall_score(y_test, rf.predict(X_test)), 'trees' :e}\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(scores2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "![recallScores2](./assets/recallScores4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Question 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### On drilling down and focusing on 'gini' random forests with between 1 and 8 trees it becomes clear that\n",
    "### increasing the number of trees is yeilding\n",
    "\n",
    "### 'a') better results\n",
    "### 'b') worse results\n",
    "### 'c') The amount the recall jumps around it is difficult to tell - There is not enough \n",
    "### ### ### Consistency in the results to say more trees are \"better\" or \"worse\"\n",
    "### Assign the character corresponding to your choice as a string to ans1\n",
    "\n",
    "### YOUR ANSWER BELOW\n",
    "\n",
    "ans1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 12",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "While it might be tempting to try to tune-and-tune-and-tune hyper-parameters to increase scores, in many cases (as in the example above) hyper-parameter tuning mostly results in ***not** creating a better model*, but a model that does a better job of predicting the test set.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
